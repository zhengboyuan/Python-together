import streamlit as st
import pandas as pd
import os
import json
from openai import OpenAI
from collections import defaultdict

# Deepseek APIé…ç½®
deepseek_key = "sk-5e2d18a842094fdead32a0a2b259439f"
client = OpenAI(api_key=deepseek_key, base_url="https://api.deepseek.com")

def test_deepseek_connection():
    """æµ‹è¯•Deepseek APIè¿æ¥"""
    try:
        test_prompt = "è¯·å›å¤'APIè¿æ¥æ­£å¸¸'"
        response = client.chat.completions.create(
            model="deepseek-reasoner",
            messages=[{"role": "user", "content": test_prompt}],
            max_tokens=10
        )
        if response.choices[0].message.content == "APIè¿æ¥æ­£å¸¸":
            st.success("âœ… Deepseek APIè¿æ¥æ­£å¸¸")
        else:
            st.warning(f"âš ï¸ APIè¿”å›å¼‚å¸¸: {response.choices[0].message.content}")
    except Exception as e:
        st.error(f"âŒ Deepseek APIè¿æ¥å¤±è´¥: {str(e)}")

# Streamlitç•Œé¢é…ç½®ï¼ˆåªæ‰§è¡Œä¸€æ¬¡ï¼‰
st.set_page_config(page_title="å·¥ä½œæ€»ç»“åˆ†æç³»ç»Ÿ", layout="wide")
st.title("ğŸ“Š å·¥ä½œæ—¥æŠ¥æ€»ç»“åˆ†æ")

# åˆå§‹åŒ–session_state
if 'report_df' not in st.session_state:
    st.session_state.report_df = None
if 'last_uploaded' not in st.session_state:
    st.session_state.last_uploaded = None

# æµ‹è¯•APIè¿æ¥
test_deepseek_connection()

def extract_keywords_for_person(person_name, summaries):
    """ä½¿ç”¨Deepseekåˆ†æä¸€ä¸ªäººçš„æ‰€æœ‰å·¥ä½œæ€»ç»“"""
    try:
        combined_text = "\n".join([f"{i+1}. {s}" for i, s in enumerate(summaries)])
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªå·¥ä½œåˆ†æåŠ©æ‰‹ï¼Œè¯·åˆ†æä¸€ä¸ªäººä¸€æ®µæ—¶é—´çš„å·¥ä½œæ€»ç»“ã€‚
1. æå–ä¸»è¦å·¥ä½œä»»åŠ¡ï¼Œæ¯ä¸ªä»»åŠ¡ç”¨3-5ä¸ªå­—çš„çŸ­è¯­æè¿°
2. ç›¸ä¼¼ä»»åŠ¡åº”è¿›è¡Œåˆå¹¶ï¼ˆå¦‚'å¤„ç†å™ªå£°'ã€'å™ªå£°æŠ•è¯‰å¤„ç†'ã€'å™ªéŸ³æµ‹è¯•'ç»Ÿä¸€å½’ä¸º'å™ªå£°å¤„ç†'ï¼‰
3. åˆå¹¶è§„åˆ™ï¼šç›¸åŒé¢†åŸŸçš„å·¥ä½œä½¿ç”¨æœ€ç®€çŸ­çš„æ ‡å‡†åŒ–è¡¨è¿°
4. å¿…é¡»è¿”å›çº¯JSONæ ¼å¼ï¼Œç¤ºä¾‹ï¼š{'tasks': ['ä»»åŠ¡1','ä»»åŠ¡2']}"""
        
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"è¯·åˆ†æ{person_name}çš„å·¥ä½œæ€»ç»“ï¼Œæå–æ ‡å‡†åŒ–çš„å·¥ä½œä»»åŠ¡:\n{combined_text}"}
            ],
            temperature=0.2,
            max_tokens=1000,
            response_format={"type": "json_object"}
        )
        result = response.choices[0].message.content
        try:
            data = json.loads(result)
            if isinstance(data, dict) and 'tasks' in data:
                return data['tasks']
            return []
        except json.JSONDecodeError:
            st.error(f"è§£æ{person_name}çš„å·¥ä½œåˆ†æç»“æœå¤±è´¥ï¼Œè¿”å›å†…å®¹: {result}")
            return []
    except Exception as e:
        st.error(f"åˆ†æ{person_name}å·¥ä½œå‡ºé”™: {e}")
        return []

def analyze_work_history(df):
    """åˆ†æå·¥ä½œå†å²ï¼Œè®°å½•æ¯é¡¹å·¥ä½œçš„é¦–æ¬¡å’Œæœ€åä¸€æ¬¡å‡ºç°"""
    work_records = []
    
    # æŒ‰äººå‘˜åˆ†ç»„å¹¶æŒ‰æ—¶é—´æ’åº
    grouped = df.groupby('å§“å')
    
    for name, group in grouped:
        group = group.sort_values('æäº¤æ—¶é—´')
        valid_summaries = [s for s in group['ä»Šæ—¥æ€»ç»“'] if pd.notna(s)]
        
        if not valid_summaries:
            continue
            
        st.write(f"æ­£åœ¨åˆ†æ: {name} çš„å·¥ä½œæ€»ç»“")
        keywords = extract_keywords_for_person(name, valid_summaries)
        st.write(f"æå–åˆ°å…³é”®è¯: {keywords}")
        
        # è®°å½•æ¯é¡¹å·¥ä½œçš„å®é™…æ—¥æœŸ
        for idx, work in enumerate(keywords):
            record_idx = idx % len(group)  # ä½¿ç”¨å¾ªç¯ç´¢å¼•é¿å…è¶Šç•Œ
            work_records.append({
                'work': work,
                'person': name,
                'date': group.iloc[record_idx]['æäº¤æ—¶é—´']
            })
    
    # æŒ‰å·¥ä½œå†…å®¹åˆ†ç»„ç»Ÿè®¡
    work_stats = defaultdict(list)
    for record in work_records:
        work_stats[record['work']].append(record)
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    report = []
    for work, records in work_stats.items():
        dates = [r['date'] for r in records]
        persons = list(set([r['person'] for r in records]))
        
        person_counts = defaultdict(int)
        for r in records:
            person_counts[r['person']] += 1
        main_person = max(person_counts.items(), key=lambda x: x[1])[0]
        
        report.append({
            'å·¥ä½œå†…å®¹': work,
            'è´Ÿè´£äºº': main_person,
            'å¼€å§‹æ—¶é—´': min(dates),
            'ç»“æŸæ—¶é—´': max(dates),
            'å‡ºç°æ¬¡æ•°': len(dates),
            'æ¶‰åŠäººå‘˜': ','.join(persons)
        })
    
    return pd.DataFrame(report)

# ä¸»ç•Œé¢åŠŸèƒ½

uploaded_file = st.file_uploader("ä¸Šä¼ å·¥ä½œæ€»ç»“CSVæ–‡ä»¶", type=["csv"])

if uploaded_file:
    # æ£€æŸ¥æ˜¯å¦ä¸Šä¼ äº†æ–°æ–‡ä»¶
    if uploaded_file.name != st.session_state.last_uploaded:
        st.session_state.report_df = None  # æ¸…é™¤ä¹‹å‰çš„åˆ†æç»“æœ
        st.session_state.last_uploaded = uploaded_file.name
    
    df = pd.read_csv(uploaded_file)
    with st.expander("åŸå§‹æ•°æ®é¢„è§ˆ"):
        st.dataframe(df.head())
    
    if st.button("å¼€å§‹åˆ†æ"):
        with st.spinner("æ­£åœ¨åˆ†æä¸­ï¼Œè¯·ç¨å€™..."):
            # ä¿å­˜åˆ†æç»“æœåˆ°session_state
            st.session_state.report_df = analyze_work_history(df)
    
    # å¦‚æœå·²æœ‰åˆ†æç»“æœï¼Œæ˜¾ç¤ºåˆ†ææŠ¥å‘Šå’Œç­›é€‰æ§ä»¶
    if st.session_state.report_df is not None:
        report_df = st.session_state.report_df
        st.subheader("åˆ†æç»“æœ")
        st.dataframe(report_df)
        
        st.subheader("æ•°æ®ç­›é€‰")
        col1, col2 = st.columns(2)
        
        with col1:
            selected_person = st.multiselect(
                "æŒ‰è´Ÿè´£äººç­›é€‰",
                options=report_df['è´Ÿè´£äºº'].unique(),
                default=report_df['è´Ÿè´£äºº'].unique()
            )
        
        with col2:
            selected_work = st.multiselect(
                "æŒ‰å·¥ä½œå†…å®¹ç­›é€‰", 
                options=report_df['å·¥ä½œå†…å®¹'].unique(),
                default=report_df['å·¥ä½œå†…å®¹'].unique()
            )
        
        # åº”ç”¨ç­›é€‰æ¡ä»¶ï¼ˆç®€åŒ–é€»è¾‘ï¼‰
        person_filter = report_df['è´Ÿè´£äºº'].isin(selected_person) if selected_person else True
        work_filter = report_df['å·¥ä½œå†…å®¹'].isin(selected_work) if selected_work else True
        
        # åº”ç”¨ç­›é€‰æ¡ä»¶
        filtered_df = report_df[person_filter & work_filter]
        
        if not filtered_df.empty:
            st.dataframe(filtered_df)
        else:
            st.warning("æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„æ•°æ®ï¼Œè¯·è°ƒæ•´ç­›é€‰æ¡ä»¶")
        
        st.download_button(
            label="ä¸‹è½½åˆ†æç»“æœ",
            data=filtered_df.to_csv(index=False, encoding='utf-8-sig'),
            file_name="å·¥ä½œå†å²åˆ†ææŠ¥å‘Š.csv",
            mime="text/csv"
        )


with st.expander("ä½¿ç”¨è¯´æ˜"):
    st.markdown("""
    1. ä¸Šä¼ åŒ…å«å·¥ä½œæ€»ç»“çš„CSVæ–‡ä»¶ï¼ˆéœ€åŒ…å«'å§“å'ã€'æäº¤æ—¶é—´'å’Œ'ä»Šæ—¥æ€»ç»“'åˆ—ï¼‰
    2. ç‚¹å‡»"å¼€å§‹åˆ†æ"æŒ‰é’®
    3. ä½¿ç”¨ç­›é€‰åŠŸèƒ½æŸ¥çœ‹ç‰¹å®šäººå‘˜æˆ–å·¥ä½œå†…å®¹
    4. ç‚¹å‡»"ä¸‹è½½åˆ†æç»“æœ"ä¿å­˜æŠ¥å‘Š
    """)
