# -*- coding: utf-8 -*-
"""
åŠŸç‡æ•°æ®åˆ†æ Web åº”ç”¨
åŸºäº Streamlit çš„äº¤äº’å¼åŠŸç‡æ•°æ®åˆ†æå·¥å…·

åŠŸèƒ½ï¼š
1. æ”¯æŒç”¨æˆ·ç›´æ¥ç²˜è´´CSVæ ¼å¼æ•°æ®
2. å®æ—¶æ•°æ®é¢„è§ˆå’ŒéªŒè¯
3. 24å°æ—¶åŠŸç‡æ›²çº¿åˆ†æ
4. ç»Ÿè®¡ä¿¡æ¯å±•ç¤º
5. é”™è¯¯å¤„ç†å’Œç”¨æˆ·æŒ‡å¯¼

ä½œè€…: æ•°æ®åˆ†æåŠ©æ‰‹
åˆ›å»ºæ—¶é—´: 2025-06-16
"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import io
import platform
from datetime import datetime

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="åŠŸç‡æ•°æ®åˆ†æå·¥å…·",
    page_icon="âš¡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# æ ¹æ®æ“ä½œç³»ç»Ÿè®¾ç½®ä¸­æ–‡å­—ä½“
system = platform.system()
if system == 'Darwin':  # macOS
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Hiragino Sans GB', 'STHeiti']
elif system == 'Windows':  # Windows
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']
else:  # Linux
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'WenQuanYi Micro Hei']

plt.rcParams['axes.unicode_minus'] = False

def get_sample_data():
    """
    ç”Ÿæˆç¤ºä¾‹æ•°æ®
    """
    sample_data = """æ—¶é—´,æ—¶åˆ»,è¾“å‡ºåŠŸç‡
01/01/90,00:00:00,0.0
01/01/90,01:00:00,0.0
01/01/90,02:00:00,0.0
01/01/90,03:00:00,0.0
01/01/90,04:00:00,0.0
01/01/90,05:00:00,10.5
01/01/90,06:00:00,320.8
01/01/90,07:00:00,1096.2
01/01/90,08:00:00,2253.1
01/01/90,09:00:00,3368.0
01/01/90,10:00:00,4162.3
01/01/90,11:00:00,4615.8
01/01/90,12:00:00,4692.7
01/01/90,13:00:00,4459.5
01/01/90,14:00:00,3833.9
01/01/90,15:00:00,2836.4
01/01/90,16:00:00,1668.1
01/01/90,17:00:00,631.9
01/01/90,18:00:00,116.2
01/01/90,19:00:00,0.0
01/01/90,20:00:00,0.0
01/01/90,21:00:00,0.0
01/01/90,22:00:00,0.0
01/01/90,23:00:00,0.0"""
    return sample_data

def detect_delimiter(csv_text):
    """
    æ™ºèƒ½æ£€æµ‹CSVæ•°æ®çš„åˆ†éš”ç¬¦
    """
    # è·å–å‰å‡ è¡Œç”¨äºåˆ†æ
    lines = csv_text.strip().split('\n')[:5]  # ä½¿ç”¨å‰5è¡Œè¿›è¡Œæ£€æµ‹
    if not lines:
        return ','

    # å®šä¹‰å€™é€‰åˆ†éš”ç¬¦åŠå…¶æ˜¾ç¤ºåç§°
    delimiters = {
        '\t': 'åˆ¶è¡¨ç¬¦(Tab)',
        ',': 'é€—å·',
        ';': 'åˆ†å·',
        '|': 'ç«–çº¿',
        ' ': 'ç©ºæ ¼'
    }

    delimiter_scores = {}

    for delimiter, name in delimiters.items():
        scores = []
        column_counts = []

        for line in lines:
            if line.strip():  # è·³è¿‡ç©ºè¡Œ
                parts = line.split(delimiter)
                column_count = len(parts)
                column_counts.append(column_count)

                # è¯„åˆ†æ ‡å‡†ï¼š
                # 1. åˆ—æ•°ä¸€è‡´æ€§ï¼ˆæ‰€æœ‰è¡Œçš„åˆ—æ•°åº”è¯¥ç›¸åŒï¼‰
                # 2. åˆ—æ•°åˆç†æ€§ï¼ˆåº”è¯¥å¤§äº1ï¼‰
                # 3. å†…å®¹åˆç†æ€§ï¼ˆåˆ†å‰²åçš„å†…å®¹ä¸åº”è¯¥å¤ªé•¿ï¼‰

                if column_count > 1:
                    scores.append(1)  # åŸºç¡€åˆ†

                    # æ£€æŸ¥åˆ†å‰²åå†…å®¹çš„åˆç†æ€§
                    reasonable_parts = sum(1 for part in parts if len(part.strip()) < 50)
                    if reasonable_parts == column_count:
                        scores.append(1)  # å†…å®¹é•¿åº¦åˆç†
                else:
                    scores.append(0)

        if column_counts:
            # æ£€æŸ¥åˆ—æ•°ä¸€è‡´æ€§
            unique_counts = set(column_counts)
            if len(unique_counts) == 1 and list(unique_counts)[0] > 1:
                consistency_score = 2  # åˆ—æ•°å®Œå…¨ä¸€è‡´ä¸”å¤§äº1
            elif len(unique_counts) <= 2:
                consistency_score = 1  # åˆ—æ•°åŸºæœ¬ä¸€è‡´
            else:
                consistency_score = 0  # åˆ—æ•°ä¸ä¸€è‡´

            total_score = sum(scores) + consistency_score
            delimiter_scores[delimiter] = {
                'score': total_score,
                'name': name,
                'columns': max(column_counts) if column_counts else 0
            }

    # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„åˆ†éš”ç¬¦
    if delimiter_scores:
        best_delimiter = max(delimiter_scores.keys(),
                           key=lambda x: delimiter_scores[x]['score'])

        # å¦‚æœæœ€é«˜åˆ†å¤§äº0ï¼Œè¿”å›è¯¥åˆ†éš”ç¬¦
        if delimiter_scores[best_delimiter]['score'] > 0:
            return best_delimiter

    # å¦‚æœæ‰€æœ‰åˆ†éš”ç¬¦å¾—åˆ†éƒ½ä¸º0ï¼Œä½¿ç”¨å¯å‘å¼æ–¹æ³•
    first_line = lines[0] if lines else ""

    # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥
    if '\t' in first_line:
        return '\t'
    elif ',' in first_line:
        return ','
    elif ';' in first_line:
        return ';'
    elif '|' in first_line:
        return '|'
    else:
        return ','  # é»˜è®¤ä½¿ç”¨é€—å·

def parse_csv_data(csv_text):
    """
    è§£æCSVæ–‡æœ¬æ•°æ®ï¼Œæ™ºèƒ½è¯†åˆ«åˆ†éš”ç¬¦
    """
    if not csv_text.strip():
        return None, "è¾“å…¥æ•°æ®ä¸ºç©º"

    # é¢„å¤„ç†ï¼šç§»é™¤å¯èƒ½çš„BOMæ ‡è®°
    csv_text = csv_text.replace('\ufeff', '')

    # æ™ºèƒ½æ£€æµ‹åˆ†éš”ç¬¦
    detected_delimiter = detect_delimiter(csv_text)

    # åˆ†éš”ç¬¦æ˜¾ç¤ºåç§°æ˜ å°„
    delimiter_names = {
        '\t': 'åˆ¶è¡¨ç¬¦(Tab)',
        ',': 'é€—å·',
        ';': 'åˆ†å·',
        '|': 'ç«–çº¿',
        ' ': 'ç©ºæ ¼'
    }

    delimiter_name = delimiter_names.get(detected_delimiter, f"'{detected_delimiter}'")

    # å°è¯•ä½¿ç”¨æ£€æµ‹åˆ°çš„åˆ†éš”ç¬¦è§£ææ•°æ®
    try:
        df = pd.read_csv(io.StringIO(csv_text), sep=detected_delimiter)

        # éªŒè¯è§£æç»“æœ
        if len(df.columns) < 2:
            raise ValueError("è§£æååˆ—æ•°å°‘äº2åˆ—")

        # æ£€æŸ¥æ˜¯å¦æœ‰ç©ºåˆ—åæˆ–é‡å¤åˆ—å
        if df.columns.duplicated().any():
            raise ValueError("å­˜åœ¨é‡å¤çš„åˆ—å")

        if any(str(col).strip() == '' for col in df.columns):
            raise ValueError("å­˜åœ¨ç©ºçš„åˆ—å")

        return df, f"âœ… æˆåŠŸä½¿ç”¨ {delimiter_name} åˆ†éš”ç¬¦è§£ææ•°æ®"

    except Exception as e:
        # å¦‚æœæ£€æµ‹çš„åˆ†éš”ç¬¦å¤±è´¥ï¼Œå°è¯•å…¶ä»–åˆ†éš”ç¬¦
        fallback_delimiters = ['\t', ',', ';', '|']

        for delimiter in fallback_delimiters:
            if delimiter == detected_delimiter:
                continue  # è·³è¿‡å·²ç»å°è¯•è¿‡çš„åˆ†éš”ç¬¦

            try:
                df = pd.read_csv(io.StringIO(csv_text), sep=delimiter)

                if len(df.columns) >= 2 and not df.columns.duplicated().any():
                    delimiter_name = delimiter_names.get(delimiter, f"'{delimiter}'")
                    return df, f"âš ï¸ ä½¿ç”¨å¤‡ç”¨åˆ†éš”ç¬¦ {delimiter_name} è§£ææ•°æ®"

            except:
                continue

        # æ‰€æœ‰åˆ†éš”ç¬¦éƒ½å¤±è´¥
        error_msg = f"""
âŒ æ•°æ®è§£æå¤±è´¥

**æ£€æµ‹åˆ°çš„åˆ†éš”ç¬¦**: {delimiter_name}
**é”™è¯¯ä¿¡æ¯**: {str(e)}

**å¯èƒ½çš„åŸå› **:
1. æ•°æ®æ ¼å¼ä¸è§„èŒƒï¼ˆåˆ—æ•°ä¸ä¸€è‡´ï¼‰
2. åŒ…å«ç‰¹æ®Šå­—ç¬¦æˆ–ç¼–ç é—®é¢˜
3. ç¼ºå°‘è¡¨å¤´è¡Œ
4. åˆ†éš”ç¬¦ä½¿ç”¨ä¸ä¸€è‡´

**å»ºè®®è§£å†³æ–¹æ¡ˆ**:
1. ç¡®ä¿æ•°æ®åŒ…å«è¡¨å¤´è¡Œ
2. æ£€æŸ¥æ¯è¡Œçš„åˆ—æ•°æ˜¯å¦ä¸€è‡´
3. ç¡®ä¿ä½¿ç”¨ç»Ÿä¸€çš„åˆ†éš”ç¬¦
4. å°è¯•ä½¿ç”¨ç¤ºä¾‹æ•°æ®æ ¼å¼
"""

        return None, error_msg

def validate_data(df):
    """
    éªŒè¯æ•°æ®æ ¼å¼
    """
    errors = []
    warnings = []
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—
    required_columns = ['æ—¶åˆ»', 'è¾“å‡ºåŠŸç‡']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        errors.append(f"ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
        errors.append(f"å½“å‰åˆ—å: {df.columns.tolist()}")
        return errors, warnings
    
    # æ£€æŸ¥æ•°æ®ç±»å‹
    if df['è¾“å‡ºåŠŸç‡'].dtype not in ['int64', 'float64']:
        try:
            df['è¾“å‡ºåŠŸç‡'] = pd.to_numeric(df['è¾“å‡ºåŠŸç‡'], errors='coerce')
            if df['è¾“å‡ºåŠŸç‡'].isna().any():
                warnings.append("éƒ¨åˆ†è¾“å‡ºåŠŸç‡æ•°æ®æ— æ³•è½¬æ¢ä¸ºæ•°å€¼ï¼Œå·²è®¾ä¸ºNaN")
        except:
            errors.append("è¾“å‡ºåŠŸç‡åˆ—åŒ…å«æ— æ³•è½¬æ¢ä¸ºæ•°å€¼çš„æ•°æ®")
    
    # æ£€æŸ¥æ—¶åˆ»æ ¼å¼
    try:
        # å°è¯•è§£ææ—¶åˆ»æ•°æ®
        if df['æ—¶åˆ»'].dtype == 'object':
            sample_time = str(df['æ—¶åˆ»'].iloc[0])
            if ':' not in sample_time:
                errors.append("æ—¶åˆ»æ ¼å¼é”™è¯¯ï¼Œåº”åŒ…å«å†’å·åˆ†éš”ç¬¦ï¼ˆå¦‚ï¼š12:30:00ï¼‰")
    except:
        errors.append("æ—¶åˆ»åˆ—æ•°æ®æ ¼å¼å¼‚å¸¸")
    
    # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
    if len(df) < 24:
        warnings.append(f"æ•°æ®è¡Œæ•°è¾ƒå°‘ï¼ˆ{len(df)}è¡Œï¼‰ï¼Œå»ºè®®åŒ…å«24å°æ—¶å®Œæ•´æ•°æ®")
    
    return errors, warnings

def extract_hour_data(df):
    """
    ä»æ—¶åˆ»åˆ—æå–å°æ—¶æ•°æ®
    """
    try:
        # å¦‚æœæ—¶åˆ»åˆ—æ˜¯æ—¶é—´æ ¼å¼ï¼Œéœ€è¦å…ˆè½¬æ¢ä¸ºå­—ç¬¦ä¸²
        if df['æ—¶åˆ»'].dtype == 'object':
            # å°è¯•ç›´æ¥ä»æ—¶é—´å¯¹è±¡æå–å°æ—¶
            try:
                # å¦‚æœæ˜¯æ—¶é—´å¯¹è±¡ï¼Œç›´æ¥æå–å°æ—¶
                df['å°æ—¶'] = pd.to_datetime(df['æ—¶åˆ»'], format='%H:%M:%S').dt.hour
            except:
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼ŒæŒ‰åŸæ–¹æ³•å¤„ç†
                df['å°æ—¶'] = df['æ—¶åˆ»'].astype(str).str.split(':').str[0].astype(int)
        else:
            # å…¶ä»–æƒ…å†µè½¬æ¢ä¸ºå­—ç¬¦ä¸²åå¤„ç†
            df['å°æ—¶'] = df['æ—¶åˆ»'].astype(str).str.split(':').str[0].astype(int)
        
        return True, None
        
    except Exception as e:
        # å¤‡ç”¨æ–¹æ³•ï¼šç›´æ¥ä»æ—¶åˆ»å­—ç¬¦ä¸²æå–å°æ—¶
        try:
            df['æ—¶åˆ»_str'] = df['æ—¶åˆ»'].astype(str)
            df['å°æ—¶'] = df['æ—¶åˆ»_str'].str[:2].astype(int)
            return True, "ä½¿ç”¨å¤‡ç”¨æ–¹æ³•æå–å°æ—¶æ•°æ®"
        except Exception as e2:
            return False, f"æå–å°æ—¶æ•°æ®å¤±è´¥: {str(e)} | å¤‡ç”¨æ–¹æ³•: {str(e2)}"

def calculate_hourly_stats(df):
    """
    è®¡ç®—æ¯å°æ—¶ç»Ÿè®¡æ•°æ®
    """
    try:
        # è®¡ç®—æ¯å°æ—¶å¹³å‡åŠŸç‡
        hourly_avg = df.groupby('å°æ—¶')['è¾“å‡ºåŠŸç‡'].mean()
        
        # è®¡ç®—å…¶ä»–ç»Ÿè®¡ä¿¡æ¯
        hourly_max = df.groupby('å°æ—¶')['è¾“å‡ºåŠŸç‡'].max()
        hourly_min = df.groupby('å°æ—¶')['è¾“å‡ºåŠŸç‡'].min()
        hourly_std = df.groupby('å°æ—¶')['è¾“å‡ºåŠŸç‡'].std()
        hourly_count = df.groupby('å°æ—¶')['è¾“å‡ºåŠŸç‡'].count()
        
        # åˆ›å»ºç»Ÿè®¡æ±‡æ€»
        stats_df = pd.DataFrame({
            'å°æ—¶': hourly_avg.index,
            'å¹³å‡åŠŸç‡': hourly_avg.values,
            'æœ€å¤§åŠŸç‡': hourly_max.values,
            'æœ€å°åŠŸç‡': hourly_min.values,
            'æ ‡å‡†å·®': hourly_std.values,
            'æ•°æ®ç‚¹æ•°': hourly_count.values
        })
        
        return hourly_avg, stats_df, None
        
    except Exception as e:
        return None, None, f"è®¡ç®—ç»Ÿè®¡æ•°æ®æ—¶å‡ºé”™: {str(e)}"

def create_plotly_chart(hourly_avg):
    """
    ä½¿ç”¨Plotlyåˆ›å»ºäº¤äº’å¼å›¾è¡¨
    """
    try:
        # åˆ›å»ºä¸»å›¾è¡¨
        fig = go.Figure()
        
        # æ·»åŠ åŠŸç‡æ›²çº¿
        fig.add_trace(go.Scatter(
            x=hourly_avg.index,
            y=hourly_avg.values,
            mode='lines+markers',
            name='å¹³å‡åŠŸç‡',
            line=dict(color='#2E86AB', width=3),
            marker=dict(size=8, color='#A23B72', line=dict(width=2, color='white')),
            hovertemplate='<b>ç¬¬%{x}å°æ—¶</b><br>å¹³å‡åŠŸç‡: %{y:.1f}<extra></extra>'
        ))
        
        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            title={
                'text': '24å°æ—¶å¹³å‡åŠŸç‡æ›²çº¿',
                'x': 0.5,
                'xanchor': 'center',
                'font': {'size': 20, 'family': 'Arial'}
            },
            xaxis_title='å°æ—¶',
            yaxis_title='å¹³å‡è¾“å‡ºåŠŸç‡',
            xaxis=dict(
                tickmode='linear',
                tick0=0,
                dtick=1,
                range=[-0.5, 23.5]
            ),
            hovermode='x unified',
            template='plotly_white',
            height=500
        )
        
        return fig, None
        
    except Exception as e:
        return None, f"åˆ›å»ºå›¾è¡¨æ—¶å‡ºé”™: {str(e)}"

def main():
    """
    ä¸»åº”ç”¨å‡½æ•°
    """
    # é¡µé¢æ ‡é¢˜
    st.title("âš¡ åŠŸç‡æ•°æ®åˆ†æå·¥å…·")
    st.markdown("### åŸºäºç°æœ‰æ•°æ®å¤„ç†é€»è¾‘çš„Webç‰ˆæœ¬")
    st.markdown("---")

    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("ğŸ“‹ ä½¿ç”¨è¯´æ˜")
        st.markdown("""
        ### æ•°æ®æ ¼å¼è¦æ±‚ï¼š
        - å¿…é¡»åŒ…å« **æ—¶åˆ»** å’Œ **è¾“å‡ºåŠŸç‡** åˆ—
        - æ—¶åˆ»æ ¼å¼ï¼šHH:MM:SSï¼ˆå¦‚ï¼š12:30:00ï¼‰
        - è¾“å‡ºåŠŸç‡ï¼šæ•°å€¼ç±»å‹
        - å»ºè®®åŒ…å«24å°æ—¶å®Œæ•´æ•°æ®

        ### æ“ä½œæ­¥éª¤ï¼š
        1. åœ¨ä¸‹æ–¹æ–‡æœ¬æ¡†ç²˜è´´CSVæ•°æ®
        2. ç‚¹å‡»"åˆ†ææ•°æ®"æŒ‰é’®
        3. æŸ¥çœ‹åˆ†æç»“æœå’Œå›¾è¡¨

        ### æ•°æ®æ¥æºï¼š
        - æ”¯æŒä»Excelå¤åˆ¶ç²˜è´´
        - æ”¯æŒCSVæ ¼å¼æ–‡æœ¬
        - å¯ä½¿ç”¨ç¤ºä¾‹æ•°æ®æµ‹è¯•
        """)

        st.markdown("---")

        # ç¤ºä¾‹æ•°æ®æŒ‰é’®
        if st.button("ğŸ“ åŠ è½½ç¤ºä¾‹æ•°æ®", help="ç‚¹å‡»åŠ è½½24å°æ—¶åŠŸç‡æ•°æ®ç¤ºä¾‹"):
            st.session_state.sample_loaded = True

        # æ¸…é™¤æ•°æ®æŒ‰é’®
        if st.button("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰æ•°æ®", help="æ¸…é™¤è¾“å…¥æ•°æ®å’Œåˆ†æç»“æœ"):
            st.session_state.clear()
            st.rerun()

        st.markdown("---")
        st.markdown("### ğŸ“Š åŠŸèƒ½ç‰¹ç‚¹")
        st.markdown("""
        - âœ… å®æ—¶æ•°æ®éªŒè¯
        - âœ… äº¤äº’å¼å›¾è¡¨
        - âœ… è¯¦ç»†ç»Ÿè®¡åˆ†æ
        - âœ… é”™è¯¯å¤„ç†æŒ‡å¯¼
        - âœ… æ•°æ®ä¸‹è½½åŠŸèƒ½
        """)
    
    # ä¸»å†…å®¹åŒºåŸŸ
    col1, col2 = st.columns([2, 1])

    with col1:
        st.header("ğŸ“Š æ•°æ®è¾“å…¥")

        # æ•°æ®æ ¼å¼æç¤º
        with st.expander("ğŸ’¡ æ•°æ®æ ¼å¼ç¤ºä¾‹", expanded=False):
            tab1, tab2 = st.tabs(["é€—å·åˆ†éš” (CSV)", "åˆ¶è¡¨ç¬¦åˆ†éš” (Excelå¤åˆ¶)"])

            with tab1:
                st.code("""æ—¶é—´,æ—¶åˆ»,è¾“å‡ºåŠŸç‡
01/01/90,00:00:00,0.0
01/01/90,01:00:00,0.0
01/01/90,02:00:00,0.0
...
01/01/90,12:00:00,4692.7
01/01/90,13:00:00,4459.5
...""", language="csv")

            with tab2:
                st.code("""æ—¶é—´	æ—¶åˆ»	è¾“å‡ºåŠŸç‡
01/01/90	0:00	0
01/01/90	1:00	0
01/01/90	2:00	0
...
01/01/90	12:00	4692.7
01/01/90	13:00	4459.5
...""", language="text")

            st.caption("ğŸ’¡ æç¤ºï¼šæ”¯æŒé€—å·ã€åˆ¶è¡¨ç¬¦ã€åˆ†å·ç­‰å¤šç§åˆ†éš”ç¬¦ï¼Œå¯ä»¥ç›´æ¥ä»Excelè¡¨æ ¼å¤åˆ¶ç²˜è´´æ•°æ®")

        # æ•°æ®è¾“å…¥æ–‡æœ¬æ¡†
        default_data = ""
        if st.session_state.get('sample_loaded', False):
            default_data = get_sample_data()
            st.session_state.sample_loaded = False

        csv_data = st.text_area(
            "è¯·ç²˜è´´CSVæ ¼å¼çš„æ•°æ®ï¼ˆåŒ…å«è¡¨å¤´ï¼‰ï¼š",
            value=default_data,
            height=300,
            help="æ”¯æŒä»Excelå¤åˆ¶ç²˜è´´è¡¨æ ¼æ•°æ®ï¼Œç¡®ä¿åŒ…å«'æ—¶åˆ»'å’Œ'è¾“å‡ºåŠŸç‡'åˆ—",
            placeholder="æ—¶é—´,æ—¶åˆ»,è¾“å‡ºåŠŸç‡\n01/01/90,00:00:00,0.0\n01/01/90,01:00:00,0.0\n..."
        )
        
        # åˆ†ææŒ‰é’®
        analyze_col1, analyze_col2 = st.columns([1, 1])

        with analyze_col1:
            if st.button("ğŸ” åˆ†ææ•°æ®", type="primary", use_container_width=True):
                if csv_data.strip():
                    with st.spinner("æ­£åœ¨åˆ†ææ•°æ®..."):
                        # è§£ææ•°æ®
                        df, parse_error = parse_csv_data(csv_data)

                        if df is None:
                            st.error(parse_message)

                            # æä¾›åˆ†éš”ç¬¦æ£€æµ‹å¸®åŠ©
                            st.markdown("### ğŸ” åˆ†éš”ç¬¦æ£€æµ‹å¸®åŠ©")

                            # æ˜¾ç¤ºåŸå§‹æ•°æ®çš„å‰å‡ è¡Œç”¨äºè¯Šæ–­
                            lines = csv_data.strip().split('\n')[:3]
                            if lines:
                                st.markdown("**æ‚¨çš„æ•°æ®å‰3è¡Œï¼š**")
                                for i, line in enumerate(lines, 1):
                                    st.code(f"ç¬¬{i}è¡Œ: {repr(line)}")

                                # åˆ†æå¯èƒ½çš„åˆ†éš”ç¬¦
                                st.markdown("**æ£€æµ‹åˆ°çš„å¯èƒ½åˆ†éš”ç¬¦ï¼š**")
                                delimiters_found = []
                                for delim, name in [('\t', 'åˆ¶è¡¨ç¬¦'), (',', 'é€—å·'), (';', 'åˆ†å·'), ('|', 'ç«–çº¿')]:
                                    if delim in lines[0]:
                                        count = lines[0].count(delim)
                                        delimiters_found.append(f"- {name}: {count}ä¸ª")

                                if delimiters_found:
                                    for delim_info in delimiters_found:
                                        st.write(delim_info)
                                else:
                                    st.write("- æœªæ£€æµ‹åˆ°å¸¸è§åˆ†éš”ç¬¦")

                            st.markdown("### ï¿½ è§£å†³å»ºè®®")
                            st.markdown("""
                            1. **ä»Excelå¤åˆ¶æ•°æ®æ—¶**ï¼šç›´æ¥é€‰ä¸­è¡¨æ ¼åŒºåŸŸå¤åˆ¶ç²˜è´´
                            2. **æ‰‹åŠ¨è¾“å…¥æ—¶**ï¼šç¡®ä¿ä½¿ç”¨é€—å·åˆ†éš”å„åˆ—
                            3. **æ£€æŸ¥æ ¼å¼**ï¼šç¡®ä¿æ¯è¡Œçš„åˆ—æ•°ç›¸åŒ
                            4. **æµ‹è¯•åŠŸèƒ½**ï¼šå¯ä»¥å…ˆä½¿ç”¨ç¤ºä¾‹æ•°æ®æµ‹è¯•
                            """)
                        else:
                            # éªŒè¯æ•°æ®
                            errors, warnings = validate_data(df)

                            if errors:
                                st.error("âŒ æ•°æ®éªŒè¯å¤±è´¥ï¼š")
                                for error in errors:
                                    st.error(f"â€¢ {error}")

                                st.markdown("### ğŸ”§ ä¿®æ­£å»ºè®®ï¼š")
                                st.markdown("""
                                - ç¡®ä¿åŒ…å« **æ—¶åˆ»** å’Œ **è¾“å‡ºåŠŸç‡** åˆ—
                                - æ—¶åˆ»æ ¼å¼åº”ä¸º HH:MM:SSï¼ˆå¦‚ï¼š12:30:00ï¼‰
                                - è¾“å‡ºåŠŸç‡åº”ä¸ºæ•°å€¼ç±»å‹
                                - æ£€æŸ¥åˆ—åæ˜¯å¦æ­£ç¡®ï¼ˆåŒºåˆ†å¤§å°å†™ï¼‰
                                """)
                            else:
                                # æ˜¾ç¤ºè­¦å‘Šï¼ˆå¦‚æœæœ‰ï¼‰
                                if warnings:
                                    for warning in warnings:
                                        st.warning(f"âš ï¸ {warning}")

                                # å­˜å‚¨æ•°æ®åˆ°session state
                                st.session_state.df = df
                                st.session_state.data_processed = True
                                st.success("âœ… æ•°æ®åˆ†æå®Œæˆï¼")
                else:
                    st.warning("âš ï¸ è¯·å…ˆè¾“å…¥æ•°æ®")

        with analyze_col2:
            if st.button("ğŸ§¹ æ¸…é™¤è¾“å…¥", use_container_width=True):
                st.session_state.clear()
                st.rerun()
    
    with col2:
        st.header("ğŸ“ˆ æ•°æ®é¢„è§ˆ")

        if csv_data.strip():
            df, parse_message = parse_csv_data(csv_data)
            if df is not None:
                # æ˜¾ç¤ºè§£æä¿¡æ¯
                if parse_message.startswith("âœ…"):
                    st.success(parse_message)
                elif parse_message.startswith("âš ï¸"):
                    st.warning(parse_message)

                # æ•°æ®åŸºæœ¬ä¿¡æ¯
                col_a, col_b = st.columns(2)
                with col_a:
                    st.metric("æ•°æ®è¡Œæ•°", len(df))
                with col_b:
                    st.metric("æ•°æ®åˆ—æ•°", len(df.columns))

                # åˆ—åæ˜¾ç¤º
                st.write("**åˆ—åï¼š**")
                cols_display = st.columns(min(len(df.columns), 3))
                for i, col in enumerate(df.columns):
                    with cols_display[i % 3]:
                        st.code(col)

                # æ•°æ®é¢„è§ˆ
                st.dataframe(df.head(10), use_container_width=True)
                st.caption(f"æ˜¾ç¤ºå‰10è¡Œï¼Œå…±{len(df)}è¡Œæ•°æ®")

                # å¿«é€Ÿç»Ÿè®¡
                if 'è¾“å‡ºåŠŸç‡' in df.columns:
                    try:
                        power_col = pd.to_numeric(df['è¾“å‡ºåŠŸç‡'], errors='coerce')
                        if not power_col.isna().all():
                            st.write("**åŠŸç‡æ•°æ®å¿«é€Ÿç»Ÿè®¡ï¼š**")
                            col_a, col_b = st.columns(2)
                            with col_a:
                                st.metric("æœ€å¤§å€¼", f"{power_col.max():.1f}")
                                st.metric("å¹³å‡å€¼", f"{power_col.mean():.1f}")
                            with col_b:
                                st.metric("æœ€å°å€¼", f"{power_col.min():.1f}")
                                st.metric("éé›¶å€¼", f"{(power_col > 0).sum()}")
                    except:
                        pass
            else:
                st.error("æ•°æ®æ ¼å¼é”™è¯¯ï¼Œæ— æ³•é¢„è§ˆ")
                st.markdown("**å¸¸è§é”™è¯¯ï¼š**")
                st.markdown("- ç¼ºå°‘è¡¨å¤´è¡Œ")
                st.markdown("- åˆ—åˆ†éš”ç¬¦ä¸æ˜¯é€—å·")
                st.markdown("- åŒ…å«ç‰¹æ®Šå­—ç¬¦")
        else:
            st.info("è¾“å…¥æ•°æ®åå°†æ˜¾ç¤ºé¢„è§ˆ")
            st.markdown("**æ”¯æŒçš„æ•°æ®æ ¼å¼ï¼š**")
            st.markdown("- CSVæ ¼å¼æ–‡æœ¬")
            st.markdown("- Excelå¤åˆ¶çš„è¡¨æ ¼æ•°æ®")
            st.markdown("- åŒ…å«è¡¨å¤´çš„æ•°æ®")
    
    # åˆ†æç»“æœå±•ç¤º
    if st.session_state.get('data_processed', False) and 'df' in st.session_state:
        st.markdown("---")
        st.header("ğŸ“Š åˆ†æç»“æœ")
        
        df = st.session_state.df
        
        # æå–å°æ—¶æ•°æ®
        success, message = extract_hour_data(df)
        
        if not success:
            st.error(f"âŒ {message}")
        else:
            if message:
                st.info(f"â„¹ï¸ {message}")
            
            # è®¡ç®—ç»Ÿè®¡æ•°æ®
            hourly_avg, stats_df, calc_error = calculate_hourly_stats(df)
            
            if calc_error:
                st.error(f"âŒ {calc_error}")
            else:
                # æ˜¾ç¤ºå›¾è¡¨
                fig, chart_error = create_plotly_chart(hourly_avg)
                
                if chart_error:
                    st.error(f"âŒ {chart_error}")
                else:
                    st.plotly_chart(fig, use_container_width=True)
                
                # æ˜¾ç¤ºå…³é”®ç»Ÿè®¡ä¿¡æ¯
                st.subheader("ğŸ“Š å…³é”®æŒ‡æ ‡")
                col1, col2, col3, col4 = st.columns(4)

                with col1:
                    st.metric(
                        "æœ€å¤§å¹³å‡åŠŸç‡",
                        f"{hourly_avg.max():.1f}",
                        f"ç¬¬{hourly_avg.idxmax()}å°æ—¶"
                    )

                with col2:
                    st.metric(
                        "æ€»å¹³å‡åŠŸç‡",
                        f"{hourly_avg.mean():.1f}"
                    )

                with col3:
                    st.metric(
                        "åŠŸç‡æ ‡å‡†å·®",
                        f"{hourly_avg.std():.1f}"
                    )

                with col4:
                    # è®¡ç®—æœ‰æ•ˆå‘ç”µå°æ—¶æ•°
                    active_hours = (hourly_avg > 0).sum()
                    st.metric(
                        "æœ‰æ•ˆå‘ç”µå°æ—¶",
                        f"{active_hours}å°æ—¶"
                    )

                # åŠŸç‡åˆ†å¸ƒåˆ†æ
                st.subheader("ğŸ” åŠŸç‡åˆ†å¸ƒåˆ†æ")

                # åˆ›å»ºåŠŸç‡ç­‰çº§åˆ†æ
                power_ranges = {
                    "æ— åŠŸç‡è¾“å‡º (0)": (hourly_avg == 0).sum(),
                    "ä½åŠŸç‡ (0-1000)": ((hourly_avg > 0) & (hourly_avg <= 1000)).sum(),
                    "ä¸­åŠŸç‡ (1000-3000)": ((hourly_avg > 1000) & (hourly_avg <= 3000)).sum(),
                    "é«˜åŠŸç‡ (>3000)": (hourly_avg > 3000).sum()
                }

                range_col1, range_col2 = st.columns(2)
                with range_col1:
                    for range_name, count in power_ranges.items():
                        st.write(f"**{range_name}**: {count} å°æ—¶")

                with range_col2:
                    # å³°å€¼æ—¶æ®µåˆ†æ
                    peak_hours = hourly_avg[hourly_avg > hourly_avg.mean()].index.tolist()
                    if peak_hours:
                        st.write(f"**å³°å€¼æ—¶æ®µ**: {min(peak_hours)}-{max(peak_hours)}å°æ—¶")
                        st.write(f"**å³°å€¼æŒç»­**: {len(peak_hours)} å°æ—¶")

                    # å‘ç”µæ•ˆç‡
                    total_possible = 24 * hourly_avg.max()
                    actual_total = hourly_avg.sum()
                    efficiency = (actual_total / total_possible * 100) if total_possible > 0 else 0
                    st.write(f"**å‘ç”µæ•ˆç‡**: {efficiency:.1f}%")
                
                # è¯¦ç»†ç»Ÿè®¡è¡¨æ ¼
                st.subheader("ğŸ“‹ è¯¦ç»†ç»Ÿè®¡æ•°æ®")
                st.dataframe(stats_df, use_container_width=True)
                
                # ä¸‹è½½æŒ‰é’®
                csv_download = stats_df.to_csv(index=False, encoding='utf-8-sig')
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ç»Ÿè®¡æ•°æ® (CSV)",
                    data=csv_download,
                    file_name=f"åŠŸç‡ç»Ÿè®¡_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                    mime="text/csv"
                )

if __name__ == "__main__":
    main()
